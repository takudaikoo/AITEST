# 08. GoogleのAI原則（AI Principles）を知る

## 1. はじめに
AIは強力な技術ですが、使い方を誤ると社会に悪影響を与える可能性もあります。
Googleは、AIを開発・提供する企業としての責任を果たすため、7つの「**AI原則（AI Principles）**」を定め、これに従ってGeminiなどの製品を開発しています。

![GoogleのAI原則](./../attachments/01_08_ai_principles.png)

---

## 2. 7つの原則（要約）
1.  **社会的有益性**: 社会にプラスになることに利用する。
2.  **不公平なバイアスの回避**: 人種、性別、収入などによる不当な差別を助長しない。
3.  **安全性**: 事故が起きないよう、安全設計を徹底する。
4.  **説明責任**: AIがなぜその判断をしたのか、人間に説明できるようにする。
5.  **プライバシー**: ユーザーのデータを守り、プライバシーを尊重する。
6.  **科学的卓越性**: 高い科学的基準に基づいて技術開発を行う。
7.  **利用提供の制限**: 有害な目的や、監視、兵器などにはAIを提供しない。

## 3. なぜこれを知る必要があるのか？
「開発者じゃないから関係ない」のではありません。
これらの原則を知ることで、**「Geminiがなぜ特定の質問に答えてくれないのか（回答を拒否するのか）」**が理解できるようになります。

例えば、「爆弾の作り方を教えて」と聞いてもGeminiは答えません。これは「安全性」や「有害な目的の制限」という原則に基づき、意図的にガードがかけられているからです。

---

## 4. まとめ
AIは「何でもできる魔法」ではなく、**「倫理的なルールの上で動くツール」**です。
このルールがあるからこそ、私たちは職場でも安心してAIを利用することができるのです。