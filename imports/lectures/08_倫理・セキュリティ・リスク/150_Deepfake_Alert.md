# 150. ディープフェイクへの警戒とリテラシー

## 1. はじめに
「社長からのビデオメッセージで『緊急送金してくれ』と言われた」
送金したら、実は詐欺師がAIで作った偽動画だった。
そんな事件が現実に起きています。
**「ディープフェイク（AIによるなりすまし合成）」**を見抜く目が、現代の護身術です。

![ディープフェイク警戒](./../attachments/08_150_deepfake_literacy_1769363936870.png)

## 2. 見抜くポイント
今の技術でも完全ではありません。
*   **瞬き**: 不自然に少ない、または無い。
*   **口元**: 音声と唇の同期が微妙にズレている。
*   **画質**: 顔だけ高精細で、輪郭の部分がぼやけている。

## 3. 合言葉を決める
技術は進化し、いずれ見抜けなくなります。
重要なのは、アナログな対策です。
「緊急時は必ず電話で**『合言葉』**を確認する」といった、人間同士のルールを決めておきましょう。

---

## 4. まとめ
「百聞は一見に如かず」は終わりました。
「目に見えるもの」ではなく、「信頼できるルート（本人確認）」だけを信じる。
ゼロトラスト（誰も信用しない）の思考が必要です。

---

content,question_type,option_1,option_2,option_3,option_4,correct_indices,explanation,difficulty,points,tags,category
"AI技術で作成された本物そっくりの偽動画・音声（ディープフェイク）による詐欺被害（オレオレ詐欺のAI版など）を防ぐための、最も確実な対策はどれですか？",single,"動画の画質を上げる","AIの電源を切る","「映像や音声だけで本人と信じない」という意識を持ち、金銭が絡む緊急時は必ず本人しか知らない「合言葉」を確認したり、折り返し電話をする","顔のシワの数を数える",3,"技術的な真贋判定はいたちごっこです。最終的には「映像は偽造できる」という前提に立ち、合言葉や多経路での確認（電話とメールの併用など）というアナログな運用ルールが最強の防御になります。",1,10,"ディープフェイク,詐欺対策,リテラシー","倫理・セキュリティ・リスク"

