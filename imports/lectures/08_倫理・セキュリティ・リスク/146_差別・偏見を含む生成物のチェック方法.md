# 146. 差別・偏見を含む生成物のチェック方法

## 1. はじめに
AIはネット上の大量のデータを学習しています。
つまり、ネット上の**「人間の偏見（バイアス）」**も学習してしまっています。
出力結果に、無意識の差別が含まれていないかチェックする目が必要です。

![バイアスチェック](./../attachments/08_146_bias_check_1769363868164.png)

## 2. バイアスの例
*   **ジェンダー**: 「CEO」を描かせると男性ばかり、「秘書」は女性ばかり。
*   **人種**: 「美しい肌」というと白人の肌ばかり。
*   **ステレオタイプ**: 「日本人」というと着物を着ている。

## 3. 人間によるフィルタリング
AIが出したドラフトをそのまま公開せず、
「特定の性別や人種に偏っていないか？」
「誰かを傷つける表現になっていないか？」
を人間が確認し、プロンプトで「多様な人種を含めて」と修正指示を出します。

---

## 4. まとめ
AIは鏡です。社会の不完全さを映し出します。
その鏡に映った歪みを、そのまま再生産しないのが、これからのクリエイターの倫理観です。