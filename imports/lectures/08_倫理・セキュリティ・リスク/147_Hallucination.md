# 147. 誤情報（ハルシネーション）の拡散防止責任

## 1. はじめに
「AIがそう言ったから」
これは言い訳になりません。
AIがもっともらしく嘘をつく**「ハルシネーション（幻覚）」**。
それをチェックせずにSNSや仕事で拡散してしまった場合、責任を負うのは**AIではなく、あなた（発信者）**です。

![ハルシネーション対策](./../attachments/08_147_hallucination_warning_1769363888357.png)

## 2. ファクトチェックの責任
AIが書いた記事、生成したコード、翻訳した文章。
全てにおいて「裏取り（事実確認）」が必須です。
特に、人名、数字、URL、歴史的事実は間違いが多いポイントです。

## 3. 信頼を失わないために
一度でもデマを流せば、あなたの信頼は地に落ちます。
「AIは優秀なアシスタントだが、たまに知ったかぶりをする」と認識し、最終確認（承認）は人間が行うフローを徹底しましょう。

---

## 4. まとめ
AI時代において、情報の「量」は価値を持ちません。AIが無限に出せるからです。
価値があるのは、人間が保証した情報の「質（正確性）」だけです。

---

content,question_type,option_1,option_2,option_3,option_4,correct_indices,explanation,difficulty,points,tags,category
"生成AIが事実と異なる情報（ハルシネーション）を出力し、それをユーザーがそのままSNSや業務で発信して問題が起きた場合、その責任は誰にありますか？",single,"AIを開発した企業","AI自身","誤情報を確認せずに発信したユーザー（利用者）","インターネットプロバイダ",3,"AIは道具であり、最終的な発信責任は利用者にあります。AIの回答には誤りが含まれる前提で、必ずファクトチェック（裏取り）を行うのが利用者の義務です。",1,10,"ハルシネーション,責任,リテラシー","倫理・セキュリティ・リスク"

