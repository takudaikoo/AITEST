content,question_type,option_1,option_2,option_3,option_4,correct_indices,explanation,difficulty,points,tags,category
"AIが出力するテキストや画像に含まれる可能性がある「バイアス（偏見）」への対処として、利用者が心がけるべきことはどれですか？",single,"AIの結果は絶対的に中立なので、そのまま採用する","「CEO＝男性」「看護師＝女性」といった、学習データ由来のステレオタイプや偏りが出力される可能性があることを認識し、人間が多様性の観点からチェック・修正する","偏見をなくすためにAIの使用を禁止する","バイアスがあるAIを破壊する",2,"AIは過去のデータ（ウェブ上のテキスト等）に含まれる社会的偏見を反映します。ダイバーシティ＆インクルージョン（D&I）の観点から、出力結果が公平で包括的かを確認・補正するのは人間の役割です。",1,10,"バイアス,倫理,多様性","倫理・セキュリティ・リスク"